%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tufte Essay
% LaTeX Template
% Version 2.0 (19/1/19)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% The Tufte-LaTeX Developers (https://www.ctan.org/pkg/tufte-latex)
% Vel (vel@LaTeXTemplates.com)
%
% License:
% Apache License, version 2.0
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper]{tufte-handout} % Use A4 paper by default, remove 'a4paper' for US letter

\usepackage{graphicx} % Required for including images
\setkeys{Gin}{width=\linewidth, totalheight=\textheight, keepaspectratio} % Default images settings
\graphicspath{{Figures/}{./}} % Specifies where to look for included images (trailing slash required)

\usepackage{amsmath, amsfonts, amssymb, amsthm} % For math equations, theorems, symbols, etc
\usepackage{units} % Non-stacked fractions and better unit spacing

\usepackage{booktabs} % Required for better horizontal rules in tables

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{Notes on Parallel Computing}

\author{Filippo Mazzarotto}

\date{A.Y. 2024/2025} % Date, use \date{} for no date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

%----------------------------------------------------------------------------------------
%	ABSTRACT/SUMMARY
%----------------------------------------------------------------------------------------

\begin{abstract}
	\textbf{Abstract:} 
\end{abstract}

\section{Introduction}

small histroy on parallel computers
explicit and implicit parallelism
Parallel computing is superset of non-parallel computing
GHz can't go up, so we need to go wide


top-500 \cite{top500}

importance of network, as movement is the bottleneck
importance of power consumption and how it went down

Node 6

Seymour Cray \cite{crey_seymour}

\subsection{Important Tasks}

Physiscs, QED, QCD
Complex numbers for QCD could be computend in-chip with boolean gates, but trying this optimization isn't good for general purpose computing
String theory requires even more computing power

Astronomy
simulations of the universe, with clusters of galaxies

Biology
Proteing folding IBM 2002\cite{ibm_protein_folding}, Alphafold 2020 \cite{alphafold}

Neuroscience
Our brain has $10^{11}$ neurons, $10^{15}$ synapses, with $10^{18}$ operations per second
Human braing simulation is desired but not feasible yet.

AI and ML
LLMs are very large, with $10^9$ parameters
Training is very expensive, with $10^19$ operations
Inference is cheaper, with $10^9$ operations

Cryptography
RSA \cite{rsa} and homomorphic cryptography \cite{homomorphic_cryptography}

We don't know what makes a problem difficult to compute.

The NC class of problems is defined as those that can be solved in logarithmic time using a polynomial number of processors. Problems in NC can be efficiently solved in parallel. However, if a problem is not in NC, it might still be beneficial to solve it in parallel under certain conditions.

The Circuit Value Problem is in NC. The problem is to determine the value of a circuit given the values of the inputs. Given a number of processors equal to the number of gates, we can compute the value of the circuit in logarithmic time.

\subsection{Computing large sum, example}
without parallelism: $O(n)$

With parallelims we can do better.

Top down approach: divide and conquer, using associative property of sum we can divide the sum in half and sum the two halves in different processors. This is a recursive algorithm. The base case is when the sum is of size 2, in which case we can just return the sum. 

Bottom up approach: we can use a tree to sum the numbers. The tree is a binary tree, with the leaves being the numbers to sum. The internal nodes are the sum of the children. The root is the sum of all the numbers. This is a parallel algorithm.

Both lead to $O(\log n)$, this is true for any associative operation.


%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliography{sample.bib} % Use \nobibliography{<bib file>} if you have references but don't want to print a bibliography

\bibliographystyle{plainnat}

%----------------------------------------------------------------------------------------

\end{document}
